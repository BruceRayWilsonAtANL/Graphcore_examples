---
common_options: &common_options
  output:
    - [batchsize, 'batchsize']
    - [throughput, 'throughput']
    - [latency, 'latency']

regex_options: &regex_options
  data:
    throughput:
      regexp: 'throughput: *(.*?) samples\/sec'
    latency:
      regexp: 'latency: *(.*?) ms'

synth_regex_options: &synth_regex_options
  data:
    throughput:
      regexp: 'throughput: *(.*?) samples\/sec'

pytorch_resnet50_infer_synth_pod4:
  <<: [*common_options, *synth_regex_options]
  description: |
    Resnet50 batch-sizes 1 to 80 inference on 4 IPUs using synthetic data
    created on the IPU
  parameters:
    batchsize: 1,4,16,32,64,80
  cmd: >-
    poprun
      -vv
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config resnet50
      --data synthetic
      --batch-size {batchsize}
      --iterations 20

pytorch_resnet50_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    Resnet50 batch-sizes 1 to 80 inference on 4 IPUs using data generated on the
    host
  parameters:
    batchsize: 1,2,4,16,32,64,80
  cmd: >-
    poprun
      -vv
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config resnet50
      --data generated
      --batch-size {batchsize}
      --iterations 20
      --num-io-tiles 64

pytorch_resnet50_minlatency_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    Resnet50 batch-sizes 1,2,4 inference on 4 IPUs using data generated on the
    host with minimum latency
  parameters:
    batchsize: 1,2,4
  cmd: >-
    poprun
      -vv
      --mpi-local-args="
        -x POPLAR_RUNTIME_OPTIONS
        -x POPLAR_ENGINE_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config resnet50
      --data generated
      --batch-size {batchsize}
      --iterations 20
  env:
    POPLAR_ENGINE_OPTIONS: '{"exchange.enablePrefetch":"false"}'

pytorch_resnext101_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    PyTorch Resnext101 batch-sizes 1 to 16 inference on 4 IPUs using data
    generated on the host.
  parameters:
    batchsize: 1,2,4,8,16
  cmd: >-
    poprun
      -vv
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --data generated
      --batch-size {batchsize}
      --model resnext101
      --device-iterations 128
      --norm-type batch
      --precision 16.16
      --half-partial
      --eight-bit-io
      --normalization-location ipu
      --iterations 20
      --num-io-tiles 32

pytorch_resnext101_minlatency_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    PyTorch Resnext101 batch-sizes 1 to 4 inference on 4 IPUs using data
    generated on the host with minimum latency.
  parameters:
    batchsize: 1,2,4
  cmd: >-
    poprun
      -vv
      --mpi-local-args="
        -x POPLAR_RUNTIME_OPTIONS
        -x POPLAR_ENGINE_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --data generated
      --batch-size {batchsize}
      --model resnext101
      --device-iterations 128
      --norm-type batch
      --precision 16.16
      --half-partial
      --eight-bit-io
      --normalization-location ipu
      --iterations 20
  env:
    POPLAR_ENGINE_OPTIONS: '{"exchange.enablePrefetch":"false"}'

pytorch_efficientnet_b0_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B0 batch-sizes 1 to 48 inference on 4 IPUs
    using data generated on the host
  parameters:
    batchsize: 1,8,16,32,36,48
  cmd: >-
    poprun
      -vv
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b0
      --data generated
      --batch-size {batchsize}
      --iterations 200
      --num-io-tiles 64
      --dataloader-worker 16

pytorch_efficientnet_b0_minlatency_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B0 batch-sizes 1 to 4 inference on 4 IPUs
    using data generated on the host, configured for min latency
  parameters:
    batchsize: 1,2,4
  cmd: >-
    poprun
      -vv
      --mpi-local-args="
        -x POPLAR_RUNTIME_OPTIONS
        -x POPLAR_ENGINE_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b0
      --data generated
      --batch-size {batchsize}
      --iterations 200
  env:
    POPLAR_ENGINE_OPTIONS: '{"exchange.enablePrefetch":"false"}'


pytorch_efficientnet_b0_gn_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B0-G16-GN batch-sizes 1 to 100 inference on 4 IPUs
    using data generated on the host
  parameters:
    batchsize: 1,32,64,80,96,100
  cmd: >-
    poprun
      -vv
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b0-g16-gn
      --data generated
      --batch-size {batchsize}
      --iterations 200
      --num-io-tiles 64

pytorch_resnext101_minlatency_gn_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B0-G16-GN batch-sizes 1 to 4 inference on 4 IPUs
    using data generated on the host, configured for min latency
  parameters:
    batchsize: 1,2,4
  cmd: >-
    poprun
      -vv
      --mpi-local-args="
        -x POPLAR_RUNTIME_OPTIONS
        -x POPLAR_ENGINE_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b0-g16-gn
      --data generated
      --batch-size {batchsize}
      --iterations 200
  env:
    POPLAR_ENGINE_OPTIONS: '{"exchange.enablePrefetch":"false"}'

pytorch_efficientnet_b4_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B4 batch-sizes 1 to 10 inference on 4 IPUs
    using data generated on the host
  parameters:
    batchsize: 1,4,6,8,10
  cmd: >-
    poprun
      -vv
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b4
      --data generated
      --batch-size {batchsize}
      --iterations 200
      --num-io-tiles 0

pytorch_efficientnet_b4_minlatency_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B4 batch-sizes 1 to 4 inference on 4 IPUs
    using data generated on the host, configured for min latency
  parameters:
    batchsize: 1,2,4
  cmd: >-
    poprun
      -vv
      --mpi-local-args="
        -x POPLAR_RUNTIME_OPTIONS
        -x POPLAR_ENGINE_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b4
      --data generated
      --batch-size {batchsize}
      --iterations 200
  env:
    POPLAR_ENGINE_OPTIONS: '{"exchange.enablePrefetch":"false"}'

pytorch_efficientnet_b4_gn_infer_gen_pod4:
  <<: [*common_options, *regex_options]
  description: |
    EfficientNet-B4-G16-GN batch-sizes 1 to 21 inference on 4 IPUs
    using data generated on the host
  parameters:
    batchsize: 1,3,9,15,21
  cmd: >-
    poprun
      -vv
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --num-instances=4
      --num-replicas=4
    python3 run_benchmark.py
      --config efficientnet-b4-g16-gn
      --data generated
      --batch-size {batchsize}
      --iterations 200
      --num-io-tiles 0 
