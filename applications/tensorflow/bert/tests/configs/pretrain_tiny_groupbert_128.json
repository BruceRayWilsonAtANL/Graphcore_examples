{
   "task": "pretraining",
   "attention_probs_dropout_prob": 0.0,
   "hidden_act": "gelu",
   "hidden_dropout_prob": 0.0,
   "hidden_size": 128,
   "intermediate_size": 512,
   "initializer_range": 0.02,
   "max_position_embeddings": 512,
   "num_attention_heads": 2,
   "num_hidden_layers": 2,
   "vocab_size": 30400,
   "type_vocab_size": 2,
   "use_attention_projection_bias": true,
   "use_cls_layer": true,
   "use_qkv_bias": true,
   "use_prediction_bias": true,
   "pipeline_stages": [
      ["emb","pos"],
      ["hid","hid"],
      ["mlm","nsp"]
   ],
   "device_mapping":[0,0,0],

   "micro_batch_size": 1,
   "batches_per_step": 1,
   "gradient_accumulation_count": 65600,
   "num_train_steps": 7032,
   "epsilon": 1e-6,
   "beta1": 0.9,
   "beta2": 0.999,
   "lr_schedule": "polynomial_decay",
   "base_learning_rate": 0.02,
   "warmup": 2000,
   "loss_scaling": 1,
   "optimizer": "lamb",
   "weight_decay_rate": 0.01,
   "global_batch_size": 512,
   "parallel_io_threads": 16,
   "pipeline_schedule": "Grouped",
   "replicas": 1,
   "precision": "16",
   "seed": null,
   "no_outlining": false,
   "stochastic_rounding": true,
   "enable_recomputation": true,
   "fp_exceptions": false,
   "matmul_serialize_factor": 5,
   "steps_per_tensorboard": -1,
   "steps_per_ckpts": 1000,
   "steps_per_logs": 1,
   "duplicate_factor":5,

   "groupbert": true,
   "groupbert_ffn_output_groups": 4,
   "groupbert_conv_group_size": 16,
   "groupbert_conv_kernel_size": 7,
   "use_debiasing": true,
   "use_mpclip": true,

   "partials_type": "half",
   "reduction_type": "sum",
   "max_to_keep": 1,
   "available_memory_proportion": [0.2, 0.2, 0.2],
   "variable_offloading": true,
   "min_remote_tensor_size": 50000,

   "init_checkpoint": "",
   "restore_dir": "",
   "save_path": "./checkpoint/phase1",
   "seq_length": 128,
   "max_predictions_per_seq": 20,
   "static_mask": false,
   "train_file": "data/tf_wiki_no_remask/tokenised_128_dup5_no_remask/*.tfrecord"
}
