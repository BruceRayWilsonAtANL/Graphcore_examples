{
    "task": "SQuAD",
    "attention_probs_dropout_prob": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "initializer_range": 0.02,
    "intermediate_size": 4096,
    "max_position_embeddings": 512,
    "vocab_size": 30400,
    "num_attention_heads": 16,
    "num_hidden_layers": 24,
    "type_vocab_size": 2,
    "seq_length": 128,
    "use_attention_projection_bias": false,
    "use_qkv_split": true,
    "use_cls_layer": false,
    "pipeline_stages": [
        ["emb", "pos","hid","hid","hid","hid","hid","hid","hid","hid","hid","hid","hid","hid"],
        ["hid","hid","hid","hid","hid","hid","hid","hid","hid","hid","hid","hid","loc"]
     ],
    "device_mapping":[0, 1],
    "micro_batch_size": 1,
    "device_iterations": 2,
    "epsilon": 0.0001,
    "gradient_accumulation_count": 4,
    "pipeline_schedule": "Grouped",
    "replicas": 1,
    "partials_type":"half",
    "reduction_type": "mean",

    "precision": "16",
    "seed": 1234,
    "steps_per_ckpts": 100,
    "steps_per_logs": 1000,
    "weight_decay_rate": 0.01,
    "available_memory_proportion": 0.45,
    "parallel_io_threads": 1,
    "matmul_serialize_factor": 4,
    "no_outlining": false,
    "stochastic_rounding": false,
    "enable_recomputation": true,
    "fp_exceptions": false,

    "init_checkpoint": "",
    "static_mask": false,

    "variable_offloading": false,
    "do_lower_case": true,

    "output_dir": "./tmp/squad/",
    "save_path": "./checkpoint/squad",
    "vocab_file": "data/ckpts/uncased_L-12_H-768_A-12/vocab.txt",
    "predict_file": "data/squad/dev-v1.1.json",
    "tfrecord_dir": "./tmp/tf_record_cache/"
}

